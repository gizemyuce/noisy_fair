tensor([ 0.0323,  0.0032, -0.0033,  ..., -0.0054,  0.0029,  0.0027])
CMM train_err=0.0, err=44.45000076293945
1.1378129720687866
1.081709861755371
1.0309243202209473
0.9850472807884216
0.9437011480331421
0.9065312743186951
0.87320476770401
0.8434149026870728
0.8168680667877197
0.7932871580123901
0.772418737411499
0.7540172338485718
0.7378556728363037
0.7237190008163452
0.7114055156707764
0.7007280588150024
0.6915092468261719
0.6835883855819702
0.676811695098877
0.6710419654846191
0.6661534309387207
0.6620283126831055
0.6585643291473389
0.655669093132019
0.6532583236694336
0.6512594223022461
0.6496089696884155
0.6482514142990112
0.647138774394989
0.6462295055389404
0.6454893350601196
0.6448880434036255
0.6444016695022583
0.6440083980560303
0.6436917185783386
0.6434370279312134
0.6432320475578308
0.6430683135986328
0.6429376602172852
0.6428330540657043
0.6427491307258606
0.6426831483840942
0.6426296234130859
0.6425877213478088
0.6425540447235107
0.64252769947052
0.6425062417984009
0.6424896717071533
0.6424764394760132
0.6424652934074402
0.6424574851989746
0.6424505710601807
0.6424452662467957
0.6424405574798584
0.642437756061554
0.6424354314804077
0.6424328684806824
0.6424316167831421
0.6424297094345093
0.6424291133880615
0.6424282193183899
0.6424277424812317
0.6424272060394287
0.642426609992981
0.6424262523651123
0.6424260139465332
0.6424256563186646
0.6424261927604675
0.6424258947372437
0.642425537109375
0.6424256563186646
0.6424252986907959
0.6424252390861511
0.6424252986907959
0.6424254775047302
0.6424254775047302
0.6424250602722168
C:\Users\gizem\anaconda3\envs\iw\lib\site-packages\sklearn\svm\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
tensor([ 0.0748,  0.0075, -0.0076,  ..., -0.0120,  0.0070,  0.0065],
       requires_grad=True)
w=1.0, train_err=0.0, err=44.46500015258789
====================l1=========================
CMM train_err=0.0, err=7.755000114440918
3.335944414138794
3.2513511180877686
3.230457305908203
3.2187416553497314
3.2114665508270264
3.2067155838012695
3.203000545501709
3.2003631591796875
3.198850154876709
3.1972413063049316
3.195882558822632
3.194624662399292
3.193859100341797
3.1932804584503174
3.1927850246429443
3.1916942596435547
3.1914472579956055
3.191222667694092
3.1912827491760254
3.190464496612549
3.190052032470703
3.189467430114746
3.1895220279693604
3.189019203186035
3.1890358924865723
3.1885032653808594
3.1884608268737793
3.1881942749023438
3.1879239082336426
3.1879842281341553
3.187960624694824
3.1872634887695312
3.1873936653137207
3.186960458755493
3.187500476837158
3.186891794204712
3.186756134033203
3.1866703033447266
3.186800479888916
3.1864280700683594
3.1864261627197266
3.1866559982299805
3.1861751079559326
3.1862692832946777
3.185957908630371
3.185675859451294
3.186276435852051
3.1859264373779297
3.1859641075134277
3.185457468032837
3.1856493949890137
3.185535430908203
3.1854569911956787
3.1855032444000244
3.1852879524230957
3.1850547790527344
3.1850314140319824
3.1850745677948
3.1851325035095215
3.1851305961608887
3.184854507446289
3.1851820945739746
3.1848855018615723
3.1852312088012695
3.1851468086242676
3.18491792678833
3.185065269470215
3.1849045753479004
3.1849355697631836
3.1845927238464355
3.185028553009033
3.1847987174987793
3.1849827766418457
3.184387683868408
3.1851534843444824
3.1841955184936523
3.184950828552246
3.1848034858703613
3.184530258178711
3.184993267059326
3.1845245361328125
3.1843459606170654
3.184109687805176
3.1844382286071777
3.184316635131836
3.184175729751587
3.184469223022461
3.184617280960083
3.1844005584716797
3.18440842628479
3.1844215393066406
3.184436798095703
3.184138298034668
3.1847476959228516
3.18489146232605
3.1842703819274902
3.184722423553467
3.1847100257873535
3.184332847595215
3.184429168701172
w=1.0, train_err=0.0, err=3.1700000762939453