tensor([ 3.0155e-02,  3.6391e-03, -4.9032e-03,  ...,  6.2154e-04,
        -2.3408e-05, -6.6624e-04])
CMM train_err=0.0, err=46.18499755859375
1.1376163959503174
1.0814995765686035
1.0306984186172485
0.9848046898841858
0.9434427618980408
0.9062587022781372
0.8729196786880493
0.8431112766265869
0.816548228263855
0.792951226234436
0.7720656394958496
0.7536494731903076
0.7374707460403442
0.7233176231384277
0.7109885811805725
0.7002946138381958
0.691062331199646
0.6831246614456177
0.6763355731964111
0.6705520153045654
0.6656492352485657
0.6615128517150879
0.6580371260643005
0.6551308631896973
0.6527104377746582
0.6507024765014648
0.6490445733070374
0.6476790904998779
0.6465597152709961
0.645645022392273
0.6448999047279358
0.6442940831184387
0.6438038349151611
0.6434068083763123
0.6430872678756714
0.6428292393684387
0.6426231861114502
0.6424570083618164
0.6423244476318359
0.642218828201294
0.6421334147453308
0.6420661211013794
0.6420124769210815
0.6419692635536194
0.6419352889060974
0.6419076919555664
0.6418867111206055
0.6418691873550415
0.6418553590774536
0.641844630241394
0.6418355107307434
0.6418287754058838
0.6418233513832092
0.6418192982673645
0.6418159008026123
0.6418126821517944
0.6418107748031616
0.6418085098266602
0.6418073177337646
0.6418064832687378
0.6418057680130005
0.6418049931526184
0.6418042778968811
0.6418042778968811
0.641803503036499
0.6418034434318542
0.6418026089668274
0.6418025493621826
0.6418030261993408
0.6418024897575378
0.6418020129203796
0.6418026685714722
0.6418024301528931
0.6418023109436035
0.6418017745018005
0.641802191734314
0.6418021321296692
0.6418021321296692
C:\Users\gizem\anaconda3\envs\iw\lib\site-packages\sklearn\svm\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
tensor([ 7.0266e-02,  8.7931e-03, -1.1578e-02,  ...,  1.7318e-03,
        -1.1449e-05, -1.4968e-03], requires_grad=True)
w=1.0, train_err=0.0, err=46.125
====================l1=========================
CMM train_err=0.0, err=7.500000476837158
3.4322121143341064
3.4300942420959473
3.4233222007751465
3.4259281158447266
3.421403646469116
3.4225001335144043
3.424452304840088
3.422856569290161
3.4231033325195312
3.4206156730651855
3.281172037124634
3.278925895690918
3.280085563659668
3.2789549827575684
3.2784199714660645
3.280123233795166
3.2805416584014893
3.279111623764038
3.280581474304199
3.280583381652832
3.222191333770752
3.2228567600250244
3.2228758335113525
3.2222208976745605
3.2229928970336914
3.2224693298339844
3.222724437713623
3.222095251083374
3.222612142562866
3.2223987579345703
3.199770927429199
3.1994848251342773
3.1996421813964844
3.199671983718872
3.199173927307129
3.199540615081787
3.199692964553833
3.199652910232544
3.199711561203003
3.1996524333953857
3.190490484237671
3.190457344055176
3.1905322074890137
3.1904914379119873
3.190401077270508
3.1904098987579346
3.19051456451416
3.190457344055176
3.1905741691589355
3.1904406547546387
3.1868414878845215
3.186824321746826
3.1868715286254883
3.1868414878845215
Traceback (most recent call last):
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_no_imb.py", line 433, in <module>
    margin_classifiers_perf(d=5000,n=200,approx_tau=1, SNR=10, n_test=1e4, s=1, l1=True)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_no_imb.py", line 292, in margin_classifiers_perf
    while w.grad is None or torch.norm(w.grad) > 1e-3: # > 1e-5:
KeyboardInterrupt