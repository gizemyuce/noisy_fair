torch.Size([10, 50])
torch.Size([50])
CMM train_err=0.0, err=36.68000030517578
torch.Size([10, 50])
torch.Size([10, 500])
w=1.0, train_err=0.0, err=35.55000305175781
====================l1=========================
CMM train_err=0.0, err=49.415000915527344
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1.])
     con: array([], dtype=float64)
     fun: -1.0911965372273191
 message: 'Optimization terminated successfully.'
     nit: 6
   slack: array([-1.54756319e-10, -4.85732368e-10, -3.42207781e-11, -1.19648053e-10,
       -7.69533768e-11, -1.64527133e-10, -1.70983040e-10, -1.56728514e-10,
       -1.93219611e-10, -5.71967934e-11, -1.23939682e-10,  3.43168142e-12,
       -1.64863833e-10, -8.02739326e-11, -9.56886852e-12, -1.19877362e-10,
        4.90405139e-11, -1.49389678e-10,  1.99648789e-11, -1.05317912e-10,
       -2.94913394e-10, -6.65989504e-11, -8.25973684e-11, -1.91961762e-10,
       -1.96632897e-10, -7.78047324e-11, -3.77667140e-11, -1.67360717e-10,
       -3.16519114e-11, -4.77214854e-11, -7.61132193e-11, -4.73637182e-11,
       -6.32765099e-11, -1.34475433e-10, -7.57864640e-11, -2.16667549e-10,
       -1.04560996e-10, -1.58997204e-10, -9.41123556e-11, -5.75425964e-11,
       -1.38936512e-10, -1.46453039e-10,  2.26208441e-11, -1.06504611e-10,
       -8.98330923e-11, -1.05273134e-10, -1.27215666e-10, -1.67609977e-10,
       -2.21601081e-10, -6.43593780e-11,  1.99999999e+00,  1.15246389e-09,
        1.08636878e-09,  1.22393841e-09,  1.12811068e-09,  2.21653885e-09,
        1.78202047e-09,  1.32395793e-09,  1.30380436e-09,  1.09968035e-09,
        1.09123769e-09,  1.16090344e-09,  1.27936379e-09,  1.16999062e-09,
        1.15695341e-09,  1.32011572e-09,  8.98609186e-10,  1.20444618e-09,
        9.54422917e-10,  9.67953778e-10,  1.35423405e-09,  1.42118385e-09,
        1.75477564e-09,  1.32281631e-09,  1.33420830e-09,  1.21274402e-09,
        1.00756663e-09,  1.98958581e-09,  1.07170105e-09,  1.35796224e-09,
        1.14977691e-09,  1.29191729e-09,  9.93398785e-10,  1.31759990e-09,
        1.11642235e-09,  1.21851351e-09,  1.28031964e-09,  1.29831804e-09,
        1.42487843e-09,  1.21191626e-09,  1.22300170e-09,  1.26835961e-09,
        8.85314524e-10,  1.54130240e-09,  1.06124759e-09,  1.35764144e-09,
        1.14145520e-09,  1.23496640e-09,  1.61307138e-09,  1.19999772e-09,
        1.52464068e+00,  1.47507907e+00,  9.25631645e-01,  1.41165071e-01,
        5.35471792e-01,  1.62754929e+00,  1.08953690e+00,  7.86521077e-01,
        6.86273816e-01,  2.12009644e+00, -2.55473895e-08])
  status: 0
 success: True
       x: array([9.99999997e-01, 8.19098127e-10, 5.60294778e-10, 6.71793230e-10,
       6.02532027e-10, 1.19053299e-09, 9.76501756e-10, 7.40343223e-10,
       7.48511984e-10, 5.78438573e-10, 6.07588688e-10, 5.78735877e-10,
       7.22113810e-10, 6.25132274e-10, 5.83261140e-10, 7.19996539e-10,
       4.24784336e-10, 6.76917927e-10, 4.67229019e-10, 5.36635845e-10,
       8.24573723e-10, 7.43891399e-10, 9.18686504e-10, 7.57389034e-10,
       7.65420599e-10, 6.45274377e-10, 5.22666672e-10, 1.07847326e-09,
       5.51676480e-10, 7.02841864e-10, 6.12945063e-10, 6.69640503e-10,
       5.28337647e-10, 7.26037668e-10, 5.96104405e-10, 7.17590531e-10,
       6.92440318e-10, 7.28657622e-10, 7.59495391e-10, 6.34729427e-10,
       6.80969108e-10, 7.07406327e-10, 4.31346840e-10, 8.23903507e-10,
       5.75540341e-10, 7.31457286e-10, 6.34335433e-10, 7.01288190e-10,
       9.17336232e-10, 6.32178550e-10, 9.99999997e-01, 3.33365759e-10,
       5.26074000e-10, 5.52145176e-10, 5.25578651e-10, 1.02600586e-09,
       8.05518717e-10, 5.83614710e-10, 5.55292374e-10, 5.21241779e-10,
       4.83649006e-10, 5.82167558e-10, 5.57249977e-10, 5.44858342e-10,
       5.73692272e-10, 6.00119177e-10, 4.73824850e-10, 5.27528250e-10,
       4.87193898e-10, 4.31317933e-10, 5.29660329e-10, 6.77292448e-10,
       8.36089136e-10, 5.65427272e-10, 5.68787703e-10, 5.67469644e-10,
       4.84899958e-10, 9.11112544e-10, 5.20024568e-10, 6.55120379e-10,
       5.36831844e-10, 6.22276784e-10, 4.65061138e-10, 5.91562236e-10,
       5.20317941e-10, 5.00922982e-10, 5.87879322e-10, 5.69660418e-10,
       6.65383035e-10, 5.77186831e-10, 5.42032596e-10, 5.60953288e-10,
       4.53967684e-10, 7.17398897e-10, 4.85707249e-10, 6.26184152e-10,
       5.07119767e-10, 5.33678214e-10, 6.95735151e-10, 5.67819173e-10])
(50,)
<built-in method size of Tensor object at 0x0000019B6E2BE3E0>
Traceback (most recent call last):
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 564, in <module>
    margin_classifiers_perf(d=50,n=10,approx_tau=1, SNR=10, n_test=1e4, s=1, l1=True)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 271, in margin_classifiers_perf
    err_train_l1 = test_error(w, xs, ys)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 39, in test_error
    pred = x_test @ w
RuntimeError: expected scalar type Float but found Double