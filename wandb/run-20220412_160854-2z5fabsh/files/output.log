tensor([ 0.0321,  0.0007,  0.0027,  ...,  0.0024, -0.0023,  0.0012])
CMM train_err=0.0, err=44.74500274658203
1.1397194862365723
1.0837424993515015
1.0330796241760254
0.9873224496841431
0.946092426776886
0.909037709236145
0.8758211135864258
0.8461393117904663
0.8196951150894165
0.7962144613265991
0.7754398584365845
0.757129967212677
0.7410538196563721
0.7269980907440186
0.7147600650787354
0.7041518688201904
0.6949987411499023
0.6871349811553955
0.6804116368293762
0.6746901273727417
0.6698446273803711
0.6657575368881226
0.6623266339302063
0.6594599485397339
0.6570736169815063
0.6550971865653992
0.6534650325775146
0.6521236896514893
0.6510242819786072
0.6501260995864868
0.6493955850601196
0.6488021612167358
0.6483216285705566
0.6479341387748718
0.6476215124130249
0.6473705172538757
0.6471684575080872
0.6470074653625488
0.646878182888031
0.6467750072479248
0.6466931700706482
0.6466274261474609
0.6465752124786377
0.6465335488319397
0.646501362323761
0.646474301815033
0.6464534401893616
0.6464368104934692
0.6464242339134216
0.6464136838912964
0.6464055776596069
0.6463987231254578
0.6463939547538757
0.6463897824287415
0.6463866233825684
0.6463835835456848
0.6463818550109863
0.6463801860809326
0.6463791131973267
0.6463780999183655
0.6463768482208252
0.6463764905929565
0.646375834941864
0.6463754177093506
0.6463751792907715
0.6463748216629028
0.6463747024536133
0.6463742256164551
0.6463740468025208
0.6463742256164551
0.6463739275932312
0.646373987197876
0.6463736891746521
0.646373987197876
0.6463738679885864
C:\Users\gizem\anaconda3\envs\iw\lib\site-packages\sklearn\svm\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
0.6463736295700073
0.646373987197876
tensor([ 0.0739,  0.0016,  0.0060,  ...,  0.0061, -0.0057,  0.0032],
       requires_grad=True)
w=1.0, train_err=0.0, err=44.76000213623047
====================l1=========================
CMM train_err=0.0, err=9.0649995803833
33359.3125
36251.1328125
29465.62109375
23616.55859375
18681.3359375
14652.8740234375
11472.0185546875
8668.6337890625
6543.43896484375
4870.9365234375
3583.852294921875
8684.6337890625
3422.6875
1879.388671875
61684.44140625
53838.62109375
46654.11328125
40158.9375
34337.015625
29157.88671875
24577.634765625
20564.498046875
17074.9453125
14066.431640625
11480.9560546875
9305.8408203125
7514.78369140625
6134.31689453125
4770.63232421875
3743.98388671875
26629.58203125
19410.333984375
13785.6064453125
9499.3583984375
6340.9296875
4585.82568359375
3089.1650390625
1814.3470458984375
1375.892333984375
15520.8916015625
9231.1572265625
6846.3671875
2910.7607421875
1328.6800537109375
7558.56689453125
2959.3125
3594.238525390625
25502.77734375
18569.685546875
13097.21875
8939.6474609375
8258.0478515625
4498.10546875
2635.2431640625
5364.79541015625
2190.68212890625
7919.9345703125
3525.185302734375
1201.8494873046875
55909.34375
48071.70703125
41006.9453125
34695.35546875
29109.375
24186.732421875
19929.703125
16262.458984375
13170.8720703125
10587.6396484375
8457.01953125
6707.126953125
5257.544921875
107984.1953125
100118.390625
92683.9296875
85617.8046875
78963.3359375
72695.4921875
66808.609375
61309.578125
56190.31640625
51408.61328125
46959.74609375
42801.7734375
38899.07421875
35410.03125
31954.787109375
28853.28125
26006.91015625
23373.56640625
20963.8203125
19780.03125
2250760.0
2242455.0
2234155.25
2225889.75
2217634.25
2209399.75
2201192.5
2193008.25
2184837.0
2176685.5
2168558.5
2160454.5
2152358.0
2144288.5
2136233.75
2128195.75
2120179.0
Traceback (most recent call last):
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_no_imb.py", line 434, in <module>
    margin_classifiers_perf(d=5000,n=200,approx_tau=1, SNR=10, n_test=1e4, s=1, l1=True)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_no_imb.py", line 296, in margin_classifiers_perf
    l.backward()
  File "C:\Users\gizem\anaconda3\envs\iw\lib\site-packages\torch\_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "C:\Users\gizem\anaconda3\envs\iw\lib\site-packages\torch\autograd\__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt