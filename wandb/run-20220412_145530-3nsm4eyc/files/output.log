tensor([ 3.1396e-02,  1.8751e-03,  2.3342e-03,  ..., -2.1886e-04,
        -3.0904e-03,  5.8513e-05])
CMM train_err=0.0, err=44.47999954223633
1.1379425525665283
1.0818495750427246
1.0310699939727783
0.9852009415626526
0.9438614249229431
0.9066985845565796
0.8733780980110168
0.8435940742492676
0.8170501589775085
0.7934759855270386
0.7726101875305176
0.754212498664856
0.7380538582801819
0.7239193916320801
0.7116090655326843
0.7009320259094238
0.6917158365249634
0.6837955117225647
0.677019476890564
0.6712507009506226
0.6663614511489868
0.6622374057769775
0.6587744951248169
0.6558782458305359
0.6534678339958191
0.6514689326286316
0.649819552898407
0.648461639881134
0.6473488807678223
0.6464407444000244
0.6456995010375977
0.6450994610786438
0.6446123719215393
0.6442198753356934
0.6439027786254883
0.6436485648155212
0.6434443593025208
0.643280565738678
0.6431494951248169
0.6430450677871704
0.6429619193077087
0.6428951025009155
0.642842710018158
0.6428004503250122
0.6427668333053589
0.6427400708198547
0.6427191495895386
0.6427025198936462
0.6426892280578613
0.642678439617157
0.6426702737808228
0.6426634192466736
0.6426584124565125
0.6426538825035095
0.6426510214805603
0.6426482200622559
0.6426461935043335
0.6426448225975037
0.6426438093185425
0.642642080783844
0.6426417827606201
0.6426410675048828
0.6426404714584351
0.642639696598053
0.642639696598053
0.6426396369934082
0.6426393985748291
0.6426391005516052
0.6426388025283813
0.6426388025283813
0.6426387429237366
0.6426382660865784
0.642638623714447
0.642638623714447
0.6426385045051575
0.6426382660865784
0.6426384449005127
tensor([ 0.0727,  0.0043,  0.0055,  ...,  0.0003, -0.0073, -0.0006],
       requires_grad=True)
w=1.0, train_err=0.0, err=44.3650016784668
====================l1=========================
CMM train_err=0.0, err=7.765000343322754
1628394.125
C:\Users\gizem\anaconda3\envs\iw\lib\site-packages\sklearn\svm\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
1618417.5
1608473.875
1598568.875
1588708.25
1578896.75
1569117.875
1559391.0
1549725.5
1540088.125
1536247.625
1532420.875
1528590.375
1524773.125
1520964.125
1517160.375
1513364.5
1509574.875
1505791.625
1502016.5
1500526.75
1499041.5
1497555.5
1496072.875
1494586.625
1493103.25
1491621.375
1490137.375
1488660.125
1487178.125
1486594.125
1486012.0
1485428.5
1484844.25
1484261.875
1483680.375
1483096.875
1482516.0
1481933.875
1481353.125
1481097.0
1480837.25
1480584.0
1480326.5
1480072.375
1479816.875
1479557.75
1479302.875
1479046.125
1478791.625
1478704.75
1478619.375
1478531.5
1478443.25
1478355.125
1478266.125
1478180.375
1478091.0
1478004.75
1477918.25
1477893.5
1477867.75
1477841.625
1477816.625
1477790.75
1477765.375
1477740.875
1477716.625
1477692.625
1477666.625
1477664.125
1477661.75
1477659.5
1477657.75
1477655.875
1477653.875
1477651.875
1477650.125
1477648.0
Traceback (most recent call last):
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_no_imb.py", line 433, in <module>
    margin_classifiers_perf(d=5000,n=200,approx_tau=1, SNR=10, n_test=1e4, s=1, l1=True)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_no_imb.py", line 295, in margin_classifiers_perf
    l.backward()
  File "C:\Users\gizem\anaconda3\envs\iw\lib\site-packages\torch\_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "C:\Users\gizem\anaconda3\envs\iw\lib\site-packages\torch\autograd\__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt