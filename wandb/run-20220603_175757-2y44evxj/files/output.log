

1it [00:06,  6.56s/it]
epoch 1, loss 3.9167, train acc 0.077, test acc 0.100, time 18.9 sec

1it [00:06,  6.79s/it]
0it [00:00, ?it/s]

1it [00:06,  6.62s/it]
0it [00:00, ?it/s]

1it [00:06,  6.29s/it]
0it [00:00, ?it/s]

1it [00:06,  6.55s/it]
epoch 5, loss 52.7171, train acc 0.099, test acc 0.100, time 18.1 sec

1it [00:06,  6.20s/it]
epoch 6, loss 47.8833, train acc 0.099, test acc 0.100, time 17.1 sec

1it [00:06,  6.20s/it]
epoch 7, loss 436.8756, train acc 0.099, test acc 0.100, time 17.2 sec

1it [00:06,  6.23s/it]
epoch 8, loss 167.5670, train acc 0.099, test acc 0.100, time 17.3 sec

1it [00:06,  6.23s/it]
epoch 9, loss 65.3839, train acc 0.099, test acc 0.100, time 18.3 sec
0it [00:07, ?it/s]
Traceback (most recent call last):
  File "C:\Users\gizem\Documents\GitHub\noisy_fair\resnet_fashionmnist_pytorch_mmulticlass.py", line 284, in <module>
    train_with_both_losses(n_train=int(sys.argv[1]), batch_size=int(sys.argv[1]))
  File "C:\Users\gizem\Documents\GitHub\noisy_fair\resnet_fashionmnist_pytorch_mmulticlass.py", line 243, in train_with_both_losses
    loss.backward()
  File "C:\Users\gizem\anaconda3\envs\soccer2\lib\site-packages\torch\_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "C:\Users\gizem\anaconda3\envs\soccer2\lib\site-packages\torch\autograd\__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt