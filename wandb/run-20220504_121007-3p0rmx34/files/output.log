torch.Size([10, 50])
torch.Size([50])
CMM train_err=0.0, err=33.244998931884766
torch.Size([10, 50])
torch.Size([10, 500])
w=1.0, train_err=0.0, err=34.845001220703125
====================l1=========================
CMM train_err=0.0, err=29.91499900817871
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1.])
     con: array([], dtype=float64)
     fun: -1.020728346511385
 message: 'Optimization terminated successfully.'
     nit: 7
   slack: array([-1.99561034e-10, -7.39888363e-11, -2.08699117e-10, -1.83276642e-10,
       -1.01136049e-10, -8.24565494e-11, -1.53078197e-10, -6.59650119e-11,
       -1.45321149e-10, -7.64919153e-12,  5.90676084e-11, -1.18906188e-10,
       -6.84871008e-11,  7.08530338e-11, -1.64292367e-10, -2.28697536e-10,
       -1.55950866e-10, -1.86015430e-10, -5.11100915e-11, -1.65952678e-10,
       -1.46750545e-10, -6.34634709e-11, -1.25867302e-10, -1.05338125e-10,
       -3.90385268e-11, -1.87818014e-10, -7.95610657e-11, -7.86272065e-12,
        2.59394281e-11, -4.42409546e-11, -6.20644823e-11, -1.60394926e-10,
       -1.33627646e-10, -7.23743528e-11, -1.52009602e-10, -4.18932874e-11,
       -9.34288000e-11, -5.42647965e-11,  8.47586424e-11, -1.03675495e-10,
       -2.57576043e-10, -1.29630497e-10, -2.25293125e-10, -2.15627495e-10,
       -1.04182415e-10, -1.20130053e-10, -1.09274409e-11, -2.25039312e-11,
       -1.86619416e-11,  2.25802541e-10,  1.99999999e+00,  1.38293707e-09,
        1.88089866e-09,  1.52356930e-09,  1.53687120e-09,  1.35163276e-09,
        1.71471269e-09,  1.40337455e-09,  1.35623306e-09,  1.19310892e-09,
        1.33987248e-09,  2.01340566e-09,  1.40247985e-09,  1.08395053e-09,
        1.91391054e-09,  1.66643664e-09,  1.53058702e-09,  1.51314844e-09,
        1.28103131e-09,  1.42790016e-09,  1.43187789e-09,  1.25892665e-09,
        1.42443008e-09,  1.17221482e-09,  1.40233996e-09,  1.51249457e-09,
        1.24238283e-09,  1.13009644e-09,  1.34167778e-09,  1.09621223e-09,
        1.22713741e-09,  9.98229707e-10,  1.34367038e-09,  1.39167464e-09,
        1.59914694e-09,  1.17263747e-09,  1.56263132e-09,  1.21608512e-09,
        1.10467760e-09,  1.38747656e-09,  1.82527722e-09,  1.70550021e-09,
        1.40474953e-09,  1.51584965e-09,  1.49744434e-09,  1.49976578e-09,
        1.64014977e-09,  1.46320453e-09,  1.21886953e-09,  1.11996918e-09,
        8.24560043e-01,  3.17791096e-01,  2.35452627e+00,  1.94585347e+00,
        1.32930374e+00,  3.85381430e-01,  1.04618230e-02,  1.28678607e+00,
        4.95209806e-01,  1.25740898e+00, -2.93311522e-08])
  status: 0
 success: True
       x: array([9.99999997e-01, 7.28462951e-10, 1.04479889e-09, 8.53422973e-10,
       8.19003624e-10, 7.17044657e-10, 9.33895446e-10, 7.34669779e-10,
       7.50777103e-10, 6.00379057e-10, 6.40402436e-10, 1.06615592e-09,
       7.35483477e-10, 5.06548747e-10, 1.03910145e-09, 9.47567087e-10,
       8.43268943e-10, 8.49581936e-10, 6.66070702e-10, 7.96926421e-10,
       7.89314219e-10, 6.61195059e-10, 7.75148688e-10, 6.38776474e-10,
       7.20689242e-10, 8.50156293e-10, 6.60971948e-10, 5.68979579e-10,
       6.57869178e-10, 5.70226594e-10, 6.44600947e-10, 5.79312316e-10,
       7.38649013e-10, 7.32024495e-10, 8.75578271e-10, 6.07265377e-10,
       8.28030061e-10, 6.35174958e-10, 5.09959479e-10, 7.45576029e-10,
       1.04142663e-09, 9.17565356e-10, 8.15021325e-10, 8.65738573e-10,
       8.00813376e-10, 8.09947917e-10, 8.25538605e-10, 7.42854231e-10,
       6.18765736e-10, 4.47083318e-10, 9.99999997e-01, 6.54474115e-10,
       8.36099770e-10, 6.70146331e-10, 7.17867575e-10, 6.34588107e-10,
       7.80817248e-10, 6.68704767e-10, 6.05455954e-10, 5.92729866e-10,
       6.99470045e-10, 9.47249735e-10, 6.66996376e-10, 5.77401781e-10,
       8.74809088e-10, 7.18869551e-10, 6.87318076e-10, 6.63566506e-10,
       6.14960610e-10, 6.30973743e-10, 6.42563674e-10, 5.97731588e-10,
       6.49281387e-10, 5.33438349e-10, 6.81650715e-10, 6.62338280e-10,
       5.81410882e-10, 5.61116859e-10, 6.83808606e-10, 5.25985639e-10,
       5.82536464e-10, 4.18917390e-10, 6.05021367e-10, 6.59650142e-10,
       7.23568669e-10, 5.65372089e-10, 7.34601261e-10, 5.80910161e-10,
       5.94718122e-10, 6.41900534e-10, 7.83850587e-10, 7.87934858e-10,
       5.89728201e-10, 6.50111078e-10, 6.96630962e-10, 6.89817864e-10,
       8.14611164e-10, 7.20350300e-10, 6.00103795e-10, 6.72885859e-10])
(50,)
<built-in method size of Tensor object at 0x00000244B377E890>
Traceback (most recent call last):
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 564, in <module>
    margin_classifiers_perf(d=50,n=10,approx_tau=1, SNR=10, n_test=1e4, s=1, l1=True)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 271, in margin_classifiers_perf
    err_train_l1 = test_error(w, xs, ys)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 39, in test_error
    pred = x_test @ w
RuntimeError: expected scalar type Float but found Double