torch.Size([10, 50])
torch.Size([50])
CMM train_err=0.0, err=37.16999816894531
torch.Size([10, 50])
torch.Size([10, 500])
w=1.0, train_err=0.0, err=38.80500030517578
====================l1=========================
CMM train_err=0.0, err=48.93000030517578
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1.])
     con: array([], dtype=float64)
     fun: -0.8459164085490751
 message: 'Optimization terminated successfully.'
     nit: 7
   slack: array([-7.05278280e-10, -3.27853467e-10, -2.34075476e-10, -5.54674036e-10,
       -1.37151056e-10,  4.96659147e-10, -5.06961379e-10, -1.20402379e-09,
       -5.01104148e-10, -8.03727997e-10, -5.31412348e-10, -1.21205523e-10,
       -4.47606044e-11, -6.79905967e-10,  6.01489715e-10, -4.83452534e-10,
       -8.00127931e-10, -4.76315433e-10,  7.47589076e-10, -6.14989121e-10,
        3.76315601e-10, -3.98677557e-10, -4.06496480e-10, -4.64822021e-10,
        2.54466617e-11,  4.70401959e-10, -6.71464018e-10,  7.51625496e-10,
        2.80500159e-10,  4.92038521e-11, -7.92158411e-10, -8.45457815e-10,
       -3.73115706e-10, -7.97807973e-10,  2.90207115e-10, -5.09069254e-10,
       -6.28097349e-10, -7.27665323e-10, -7.16659400e-10, -2.01060940e-11,
       -4.77137285e-10, -3.09195928e-10, -9.81316811e-10, -2.26857485e-10,
        2.83684132e-10,  1.81142145e-10, -2.76437908e-10, -3.22500102e-11,
       -8.36499786e-10, -4.18597391e-10,  1.00159224e+00,  4.09022753e-09,
        3.41613704e-09,  4.67476680e-09,  3.52804164e-09,  2.70887531e-09,
        3.98775098e-09,  7.58138079e-09,  3.92469257e-09,  4.75893329e-09,
        4.08655841e-09,  3.22863850e-09,  3.10316455e-09,  5.17128413e-09,
        2.49434429e-09,  4.06588950e-09,  4.79966047e-09,  4.58230694e-09,
        2.49372627e-09,  4.52584251e-09,  2.73891712e-09,  3.99153996e-09,
        3.69535638e-09,  4.21670109e-09,  2.99981561e-09,  2.64750259e-09,
        4.98924453e-09,  2.39604558e-09,  2.86370735e-09,  2.92859803e-09,
        1.54416161e-08,  8.99479550e-01,  4.01229610e-09,  7.40027833e-09,
        2.78180883e-09,  4.33330184e-09,  4.59099817e-09,  5.76680242e-09,
        1.28310253e-08,  3.11380746e-09,  3.74527120e-09,  3.35540482e-09,
        3.62292521e-08,  4.09653171e-09,  2.85055484e-09,  2.83987828e-09,
        3.77135916e-09,  3.02339216e-09,  9.89281354e-02,  4.07897573e-09,
        2.35357072e-01,  1.24233440e-07,  1.94680728e+00,  8.38735522e-01,
       -8.77713252e-09,  1.56652007e+00,  8.69022968e-01,  9.26374140e-01,
        6.14836750e-01,  1.46151064e+00, -7.50561890e-08])
  status: 0
 success: True
       x: array([5.00796123e-01, 2.20904050e-09, 1.82510626e-09, 2.61472042e-09,
       1.83259635e-09, 1.10610808e-09, 2.24735618e-09, 4.39270229e-09,
       2.21289836e-09, 2.78133064e-09, 2.30898538e-09, 1.67492201e-09,
       1.57396258e-09, 2.92559505e-09, 9.46427287e-10, 2.27467102e-09,
       2.79989420e-09, 2.52931118e-09, 8.73068599e-10, 2.57041581e-09,
       1.18130076e-09, 2.19510876e-09, 2.05092643e-09, 2.34076156e-09,
       1.48718448e-09, 1.08855032e-09, 2.83035427e-09, 8.22210043e-10,
       1.29160360e-09, 1.43969709e-09, 8.11688725e-09, 4.49739775e-01,
       2.19270590e-09, 4.09904315e-09, 1.24580086e-09, 2.42118555e-09,
       2.60954776e-09, 3.24723387e-09, 6.77384235e-09, 1.56695677e-09,
       2.11120424e-09, 1.83230037e-09, 1.86052844e-08, 2.16169460e-09,
       1.28343535e-09, 1.32936807e-09, 2.02389853e-09, 1.52782109e-09,
       4.94640681e-02, 2.24878656e-09, 5.00796122e-01, 1.88118703e-09,
       1.59103078e-09, 2.06004638e-09, 1.69544529e-09, 1.60276723e-09,
       1.74039480e-09, 3.18867850e-09, 1.71179421e-09, 1.97760265e-09,
       1.77757303e-09, 1.55371649e-09, 1.52920197e-09, 2.24568908e-09,
       1.54791700e-09, 1.79121848e-09, 1.99976627e-09, 2.05299575e-09,
       1.62065768e-09, 1.95542669e-09, 1.55761636e-09, 1.79643120e-09,
       1.64442995e-09, 1.87593954e-09, 1.51263114e-09, 1.55895227e-09,
       2.15889025e-09, 1.57383554e-09, 1.57210376e-09, 1.48890094e-09,
       7.32472884e-09, 4.49739775e-01, 1.81959020e-09, 3.30123518e-09,
       1.53600797e-09, 1.91211629e-09, 1.98145041e-09, 2.51956855e-09,
       6.05718295e-09, 1.54685068e-09, 1.63406696e-09, 1.52310444e-09,
       1.76239676e-08, 1.93483711e-09, 1.56711948e-09, 1.51051021e-09,
       1.74746063e-09, 1.49557108e-09, 4.94640673e-02, 1.83018917e-09])
(50,)
<built-in method size of Tensor object at 0x000001BBB2633EC0>
Traceback (most recent call last):
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 564, in <module>
    margin_classifiers_perf(d=50,n=10,approx_tau=1, SNR=10, n_test=1e4, s=1, l1=True)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 271, in margin_classifiers_perf
    err_train_l1 = test_error(w, xs, ys)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 39, in test_error
    pred = x_test @ w
RuntimeError: expected scalar type Float but found Double