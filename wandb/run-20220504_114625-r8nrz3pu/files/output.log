torch.Size([10, 50])
torch.Size([50])
CMM train_err=0.0, err=37.810001373291016
torch.Size([10, 50])
torch.Size([10, 500])
w=1.0, train_err=0.0, err=37.3650016784668
====================l1=========================
CMM train_err=0.0, err=46.94499969482422
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1.])
     con: array([], dtype=float64)
     fun: -0.8301062582373698
 message: 'Optimization terminated successfully.'
     nit: 7
   slack: array([-1.31250566e-11, -4.63942155e-12,  7.21343642e-12, -9.79501495e-12,
        2.23464128e-12,  6.58235192e-12, -7.83062055e-12, -9.63953374e-12,
       -5.48282188e-12,  5.99259959e-12,  1.56658815e-12, -7.54249019e-12,
       -5.36660288e-12, -3.35937869e-12, -8.33352557e-12, -7.31507366e-12,
       -8.76227038e-12, -1.29750369e-12, -1.27198261e-11, -5.12751125e-12,
        6.28582215e-12, -4.15066538e-12, -6.58594762e-13, -2.63322788e-12,
       -6.24877234e-12, -6.94379578e-12, -1.09391034e-11, -4.72131905e-13,
       -1.04149426e-11, -8.40302394e-12,  3.60857789e-12, -9.02943560e-12,
       -2.37581515e-12, -9.11966096e-12, -1.00932364e-11, -8.79399512e-12,
       -5.81347747e-12, -4.95605742e-12, -1.14469736e-11, -2.57744443e-13,
       -9.47393444e-12,  1.06446121e-11, -3.71086240e-12, -7.63052216e-12,
       -5.96626419e-12, -4.96056827e-12, -5.17941421e-12, -3.53540030e-12,
       -1.66060996e-12,  5.43993501e-12,  2.00000000e+00,  5.77345798e-11,
        4.14339165e-11,  8.98165321e-11,  4.57878173e-11,  4.19196524e-11,
        7.26956757e-11,  8.36146336e-11,  6.34400875e-11,  4.24175803e-11,
        4.64491218e-11,  6.96779088e-11,  6.01801414e-11,  5.43364071e-11,
        7.54296955e-11,  7.02471889e-11,  8.04352828e-11,  5.11752285e-11,
        4.95909704e-10,  6.04630144e-11,  4.20272871e-11,  5.67714101e-11,
        4.93790237e-11,  5.31804613e-11,  6.21291922e-11,  6.74354368e-11,
        1.13423541e-10,  4.92736146e-11,  1.08833758e-10,  7.69533460e-11,
        4.41349233e-11,  8.58423686e-11,  5.35551304e-11,  8.35522759e-11,
        1.03707668e-10,  7.55605239e-11,  6.32171268e-11,  5.96556957e-11,
        1.02447606e-10,  4.92958607e-11,  8.83424311e-11,  3.95156976e-11,
        5.52285957e-11,  7.43461039e-11,  6.41155130e-11,  6.11272587e-11,
        5.95656319e-11,  5.58241459e-11,  5.08578118e-11,  4.28878948e-11,
        9.24705207e-01,  4.46007818e-01,  2.81154961e-01,  8.43330026e-01,
        1.14858282e+00,  1.55673311e-01,  1.92149794e+00,  1.74572992e+00,
        1.92331165e-01,  6.42049610e-01, -1.06337095e-09])
  status: 0
 success: True
       x: array([9.99999999e-01, 3.11870007e-11, 1.71102400e-11, 4.98057735e-11,
       2.17765880e-11, 1.76686503e-11, 4.02631481e-11, 4.66270836e-11,
       3.44614547e-11, 1.82124903e-11, 2.24412668e-11, 3.86101995e-11,
       3.27733722e-11, 2.88478929e-11, 4.18816106e-11, 3.87811313e-11,
       4.45987766e-11, 2.62363661e-11, 2.54314765e-10, 3.27952628e-11,
       1.78707325e-11, 3.04610378e-11, 2.50188092e-11, 2.79068446e-11,
       3.41889823e-11, 3.71896163e-11, 6.21813222e-11, 2.48728732e-11,
       5.96243503e-11, 4.26781850e-11, 2.02631727e-11, 4.74359021e-11,
       2.79654727e-11, 4.63359684e-11, 5.69004522e-11, 4.21772595e-11,
       3.45153021e-11, 3.23058765e-11, 5.69472897e-11, 2.47768026e-11,
       4.89081828e-11, 1.44355428e-11, 2.94697291e-11, 4.09883130e-11,
       3.50408886e-11, 3.30439135e-11, 3.23725231e-11, 2.96797731e-11,
       2.62592109e-11, 1.87239799e-11, 9.99999999e-01, 2.65475791e-11,
       2.43236765e-11, 4.00107586e-11, 2.40112293e-11, 2.42510022e-11,
       3.24325276e-11, 3.69875499e-11, 2.89786328e-11, 2.42050899e-11,
       2.40078550e-11, 3.10677093e-11, 2.74067693e-11, 2.54885142e-11,
       3.35480850e-11, 3.14660576e-11, 3.58365062e-11, 2.49388624e-11,
       2.41594939e-10, 2.76677516e-11, 2.41565546e-11, 2.63103724e-11,
       2.43602145e-11, 2.52736167e-11, 2.79402099e-11, 3.02458205e-11,
       5.12422188e-11, 2.44007413e-11, 4.92094076e-11, 3.42751610e-11,
       2.38717506e-11, 3.84064665e-11, 2.55896576e-11, 3.72163075e-11,
       4.68072158e-11, 3.33832644e-11, 2.87018247e-11, 2.73498191e-11,
       4.55003161e-11, 2.45190581e-11, 3.94342484e-11, 2.50801548e-11,
       2.57588667e-11, 3.33577909e-11, 2.90746244e-11, 2.80833452e-11,
       2.71931088e-11, 2.61443728e-11, 2.45986009e-11, 2.41639149e-11])
Traceback (most recent call last):
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 557, in <module>
    margin_classifiers_perf(d=50,n=10,approx_tau=1, SNR=10, n_test=1e4, s=1, l1=True)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 264, in margin_classifiers_perf
    err_train_l1 = test_error(w, xs, ys)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 38, in test_error
    w = w / torch.norm(w)
  File "C:\Users\gizem\anaconda3\envs\iw\lib\site-packages\torch\functional.py", line 1537, in norm
    ndim = input.dim()
AttributeError: 'numpy.ndarray' object has no attribute 'dim'