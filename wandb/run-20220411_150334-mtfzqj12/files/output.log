tensor([ 0.0315, -0.0030,  0.0005,  ...,  0.0044,  0.0032, -0.0032])
CMM train_err=0.0, err=45.375
tensor([nan, nan, nan,  ..., nan, nan, nan], requires_grad=True)
w=1.0, train_err=100.0, err=100.0
tensor([nan, nan, nan,  ..., nan, nan, nan], requires_grad=True)
w=1.0, train_err=100.0, err=100.0
tensor([nan, nan, nan,  ..., nan, nan, nan], requires_grad=True)
w=1.0, train_err=100.0, err=100.0
====================l1=========================
CMM train_err=0.0, err=6.089999675750732
7194.93505859375
88348.4921875
54387.13671875
44992.58984375
20736.734375
10410.087890625
20400.005859375
18646.935546875
3673.666259765625
110391.9453125
73799.5625
47045.73046875
28367.224609375
38859.8125
12019.3779296875
5562.5390625
2871.330322265625
25744.1796875
36197.890625
12123.53515625
45819.06640625
20256.712890625
174819.8125
130500.4296875
95489.1015625
67278.5703125
46207.44921875
30667.53515625
19606.451171875
93671.125
60832.48046875
643417.3125
596095.75
550873.4375
507945.46875
467352.1875
429176.5625
393195.4375
359390.0625
327881.65625
298630.125
271492.71875
246347.515625
222981.625
201243.109375
181265.109375
162862.3125
145910.765625
130323.9296875
116033.7890625
103014.390625
91328.40625
80741.4375
71854.4609375
66131.8984375
56028.65234375
48625.66015625
42458.0234375
37310.14453125
33743.20703125
27990.875
24529.271484375
31012.18359375
20149.390625
w=1.0, train_err=100.0, err=100.0
7194.93505859375
88348.4921875
54387.13671875
44992.58984375
20736.734375
10410.087890625
20400.005859375
18646.935546875
3673.666259765625
110391.9453125
73799.5625
47045.73046875
28367.224609375
38859.8125
12019.3779296875
5562.5390625
2871.330322265625
25744.1796875
36197.890625
12123.53515625
45819.06640625
20256.712890625
174819.8125
130500.4296875
95489.1015625
67278.5703125
46207.44921875
30667.53515625
19606.451171875
93671.125
60832.48046875
643417.3125
596095.75
550873.4375
507945.46875
467352.1875
429176.5625
393195.4375
359390.0625
327881.65625
298630.125
271492.71875
246347.515625
222981.625
201243.109375
181265.109375
162862.3125
145910.765625
130323.9296875
116033.7890625
103014.390625
91328.40625
80741.4375
71854.4609375
66131.8984375
56028.65234375
48625.66015625
42458.0234375
37310.14453125
33743.20703125
27990.875
24529.271484375
31012.18359375
20149.390625
w=1.0, train_err=100.0, err=100.0
7194.93505859375
88348.4921875
54387.13671875
44992.58984375
20736.734375
10410.087890625
20400.005859375
18646.935546875
3673.666259765625
110391.9453125
73799.5625
47045.73046875
28367.224609375
38859.8125
12019.3779296875
5562.5390625
2871.330322265625
25744.1796875
36197.890625
12123.53515625
45819.06640625
20256.712890625
174819.8125
130500.4296875
95489.1015625
67278.5703125
46207.44921875
30667.53515625
19606.451171875
93671.125
60832.48046875
643417.3125
596095.75
550873.4375
507945.46875
467352.1875
429176.5625
393195.4375
359390.0625
327881.65625
298630.125
271492.71875
246347.515625
222981.625
201243.109375
181265.109375
162862.3125
145910.765625
130323.9296875
116033.7890625
103014.390625
91328.40625
80741.4375
71854.4609375
66131.8984375
56028.65234375
48625.66015625
42458.0234375
37310.14453125
33743.20703125
27990.875
24529.271484375
31012.18359375
20149.390625
w=1.0, train_err=100.0, err=100.0