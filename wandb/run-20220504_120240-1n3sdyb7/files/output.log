torch.Size([10, 50])
torch.Size([50])
CMM train_err=0.0, err=37.540000915527344
torch.Size([10, 50])
torch.Size([10, 500])
w=1.0, train_err=10.0, err=33.994998931884766
====================l1=========================
CMM train_err=0.0, err=33.84000015258789
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1.])
     con: array([], dtype=float64)
     fun: -1.2476475213304983
 message: 'Optimization terminated successfully.'
     nit: 6
   slack: array([-3.52825436e-10, -3.11949838e-10,  3.86756692e-10,  8.44138742e-11,
       -1.11291543e-10, -4.12864981e-11,  6.19113461e-11,  4.14565921e-10,
        1.95603139e-10, -1.70390059e-10,  2.37627852e-11, -3.11447175e-10,
        6.65110472e-11,  1.57318535e-10, -2.69893534e-10, -4.16566686e-10,
       -4.08204006e-10, -2.43358083e-11,  1.19229828e-10, -1.75629815e-10,
       -1.54476730e-10,  3.22423541e-10, -1.55910815e-10, -7.27160875e-11,
       -4.27396260e-10,  2.55808655e-10, -2.20143459e-10,  2.11911849e-10,
        1.18608569e-10, -2.51364109e-10,  5.34321068e-11, -2.36611851e-10,
       -3.94138450e-10, -5.94486166e-11, -2.60244427e-10, -2.84677802e-10,
       -1.77831616e-10, -4.46361143e-10, -1.58632196e-10,  4.53628083e-11,
       -1.66192721e-12,  2.33442952e-10,  2.90866573e-11, -3.51688548e-10,
       -1.14055024e-10,  2.07362276e-11, -2.79372737e-10, -3.36795016e-10,
       -8.27525630e-11, -4.63524166e-10,  1.99999999e+00,  2.31382533e-09,
        1.01771516e-09,  1.15767291e-09,  1.52437894e-09,  1.36942402e-09,
        1.18599921e-09,  9.35182671e-10,  6.67686447e-10,  2.02650291e-09,
        1.28724321e-09,  2.98221187e-09,  1.24233202e-09,  6.97004183e-10,
        1.86565251e-09,  2.32986743e-09,  2.81148751e-09,  9.92081611e-10,
        1.13987568e-09,  1.64082254e-09,  1.61236315e-09,  7.78292754e-10,
        1.56747863e-09,  1.37813974e-09,  2.29114588e-09,  9.36144347e-10,
        1.80679814e-09,  1.15331976e-09,  1.17032279e-09,  1.81831004e-09,
        1.22294534e-09,  1.84294594e-09,  7.08639579e-10,  1.49579569e-09,
        1.73635772e-09,  1.59224504e-09,  1.35335854e-09,  2.67081038e-09,
        1.48448633e-09,  1.29036929e-09,  1.29379739e-09,  8.32316941e-10,
        1.04972976e-09,  3.02291512e-09,  1.40632343e-09,  1.06890078e-09,
        1.85241893e-09,  2.00716823e-09,  1.49514693e-09,  1.80058558e-09,
        3.17818474e+00,  5.12523584e-01,  1.84917939e+00,  5.41014547e-01,
        4.95097959e-01,  1.75076116e+00,  7.29590887e-01,  1.47144934e-01,
        1.62706434e+00,  1.64591241e+00, -3.20295703e-08])
  status: 0
 success: True
       x: array([9.99999997e-01, 1.31288759e-09, 3.15479235e-10, 5.36629520e-10,
       8.17835239e-10, 7.05355259e-10, 5.62043929e-10, 2.60308375e-10,
       2.36041654e-10, 1.09844648e-09, 6.31740213e-10, 1.64682952e-09,
       5.87910485e-10, 2.69842824e-10, 1.06777302e-09, 1.37321706e-09,
       1.60984576e-09, 5.08208710e-10, 5.10322928e-10, 9.08226178e-10,
       8.83419938e-10, 2.27934607e-10, 8.61694722e-10, 7.25427915e-10,
       1.35927107e-09, 3.40167846e-10, 1.01347080e-09, 4.70703958e-10,
       5.25857109e-10, 1.03483708e-09, 5.84756619e-10, 1.03977890e-09,
       5.51389014e-10, 7.77622154e-10, 9.98301073e-10, 9.38461423e-10,
       7.65595076e-10, 1.55858576e-09, 8.21559266e-10, 6.22503239e-10,
       6.47729659e-10, 2.99436995e-10, 5.10321553e-10, 1.68730183e-09,
       7.60189228e-10, 5.24082274e-10, 1.06589583e-09, 1.17198162e-09,
       7.88949745e-10, 1.13205488e-09, 9.99999997e-01, 1.00093775e-09,
       7.02235927e-10, 6.21043394e-10, 7.06543696e-10, 6.64068761e-10,
       6.23955276e-10, 6.74874296e-10, 4.31644793e-10, 9.28056424e-10,
       6.55502998e-10, 1.33538235e-09, 6.54421532e-10, 4.27161359e-10,
       7.97879488e-10, 9.56650370e-10, 1.20164175e-09, 4.83872901e-10,
       6.29552756e-10, 7.32596363e-10, 7.28943208e-10, 5.50358147e-10,
       7.05783907e-10, 6.52711828e-10, 9.31874810e-10, 5.95976501e-10,
       7.93327341e-10, 6.82615807e-10, 6.44465678e-10, 7.83472966e-10,
       6.38188726e-10, 8.03167046e-10, 1.57250565e-10, 7.18173537e-10,
       7.38056646e-10, 6.53783621e-10, 5.87763460e-10, 1.11222462e-09,
       6.62927069e-10, 6.67866048e-10, 6.46067732e-10, 5.32879947e-10,
       5.39408211e-10, 1.33561329e-09, 6.46134205e-10, 5.44818502e-10,
       7.86523096e-10, 8.35186606e-10, 7.06197182e-10, 6.68530709e-10])
(50,)
<built-in method size of Tensor object at 0x0000012A02272B10>
Traceback (most recent call last):
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 564, in <module>
    margin_classifiers_perf(d=50,n=10,approx_tau=1, SNR=10, n_test=1e4, s=1, l1=True)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 271, in margin_classifiers_perf
    err_train_l1 = test_error(torch.squeeze(w), xs, ys)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 39, in test_error
    pred = x_test @ w
RuntimeError: expected scalar type Float but found Double