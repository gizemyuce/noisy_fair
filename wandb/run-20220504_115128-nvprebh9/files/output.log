torch.Size([10, 50])
torch.Size([50])
CMM train_err=0.0, err=38.810001373291016
torch.Size([10, 50])
torch.Size([10, 500])
w=1.0, train_err=0.0, err=37.279998779296875
====================l1=========================
CMM train_err=0.0, err=44.39500045776367
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1.])
     con: array([], dtype=float64)
     fun: -1.1443026064892572
 message: 'Optimization terminated successfully.'
     nit: 7
   slack: array([-1.55598867e-11, -1.31311365e-11, -1.25547816e-11, -2.75915807e-12,
       -8.02470341e-12, -7.40054932e-12, -6.04276572e-12, -5.47034483e-12,
       -1.08538156e-12, -1.08208931e-12, -1.13330338e-11, -4.04571512e-12,
        3.14256061e-12, -5.87775578e-12, -7.64766178e-12, -9.51134753e-12,
       -3.94038011e-12, -1.66953508e-12,  2.88937237e-12, -1.41203492e-12,
       -9.73194421e-12, -1.04519273e-12, -9.87684526e-12, -1.07773221e-11,
       -3.14936826e-12, -7.68755110e-12, -5.04066497e-13, -5.60180830e-12,
       -1.16988512e-11, -9.97520151e-12, -9.07418042e-12, -9.97530267e-12,
       -1.56185504e-11, -4.96693921e-12, -5.76099163e-12, -1.04975974e-11,
       -7.23853683e-12, -1.03003395e-11, -5.81866887e-12, -5.67768925e-12,
       -8.59854608e-12, -4.89857156e-12, -1.81094169e-11,  9.77915384e-12,
       -3.57721596e-12, -2.55023821e-12, -8.28989076e-12, -5.08068496e-12,
       -5.05388220e-12, -2.37333004e-12,  2.00000000e+00,  2.90578354e-10,
        8.33237591e-11,  5.46536275e-11,  9.30811145e-11,  6.83162578e-11,
        6.74129687e-11,  5.99395978e-11,  5.43216460e-11,  5.32808199e-11,
        7.00062806e-11,  5.83665316e-11,  4.72301857e-11,  6.60421291e-11,
        6.92312358e-11,  6.87417226e-11,  5.68438709e-11,  5.48143693e-11,
        4.86847389e-11,  5.34229880e-11,  8.12169990e-11,  5.39370497e-11,
        6.51101372e-11,  7.59528365e-11,  5.80663652e-11,  6.73859397e-11,
        4.98757598e-11,  6.71041124e-11,  1.02573824e-10,  7.61457385e-11,
        8.62424197e-11,  7.40858482e-11,  3.71356412e-10,  6.05479461e-11,
        6.37140926e-11,  9.40439465e-11,  6.78272667e-11,  8.56988544e-11,
        6.33306212e-11,  6.52705696e-11,  6.98749802e-11,  5.84771645e-11,
        8.29468359e-10,  4.13086093e-11,  5.79629352e-11,  5.37886997e-11,
        7.28405639e-11,  5.82445569e-11,  5.62681566e-11,  5.69140844e-11,
        5.51275075e-01,  1.49197066e+00,  1.04276323e+00,  2.99793601e+00,
        5.39721430e-01,  8.34702135e-01,  4.34445741e-01,  2.78403783e+00,
        2.82471210e-01,  4.83702124e-01, -1.21631349e-09])
  status: 0
 success: True
       x: array([9.99999999e-01, 1.51854745e-10, 4.79392704e-11, 2.87063928e-11,
       5.05529090e-11, 3.78584036e-11, 3.67278672e-11, 3.27049713e-11,
       2.77035138e-11, 2.71814546e-11, 4.06696572e-11, 3.12061234e-11,
       2.20438125e-11, 3.59599425e-11, 3.84394488e-11, 3.91265351e-11,
       3.03921255e-11, 2.82419522e-11, 2.28976833e-11, 2.74175115e-11,
       4.54744716e-11, 2.74911212e-11, 3.74934912e-11, 4.33650793e-11,
       3.06078667e-11, 3.75367454e-11, 2.51899132e-11, 3.63529603e-11,
       5.71363374e-11, 4.30604700e-11, 4.76583000e-11, 4.20305754e-11,
       1.93487481e-10, 3.27574426e-11, 3.47375421e-11, 5.22707720e-11,
       3.75329017e-11, 4.79995969e-11, 3.45746450e-11, 3.54741294e-11,
       3.92367631e-11, 3.16878680e-11, 4.23788888e-10, 1.57647277e-11,
       3.07700756e-11, 2.81694690e-11, 4.05652273e-11, 3.16626209e-11,
       3.06610194e-11, 2.96437072e-11, 9.99999999e-01, 1.38723609e-10,
       3.53844888e-11, 2.59472347e-11, 4.25282056e-11, 3.04578543e-11,
       3.06851015e-11, 2.72346265e-11, 2.66181322e-11, 2.60993653e-11,
       2.93366234e-11, 2.71604082e-11, 2.51863731e-11, 3.00821867e-11,
       3.07917870e-11, 2.96151875e-11, 2.64517454e-11, 2.65724171e-11,
       2.57870556e-11, 2.60054765e-11, 3.57425274e-11, 2.64459285e-11,
       2.76166460e-11, 3.25877572e-11, 2.74584985e-11, 2.98491943e-11,
       2.46858467e-11, 3.07511520e-11, 4.54374862e-11, 3.30852685e-11,
       3.85841196e-11, 3.20552728e-11, 1.77868931e-10, 2.77905034e-11,
       2.89765505e-11, 4.17731745e-11, 3.02943649e-11, 3.76992574e-11,
       2.87559762e-11, 2.97964402e-11, 3.06382170e-11, 2.67892965e-11,
       4.05679471e-10, 2.55438816e-11, 2.71928596e-11, 2.56192308e-11,
       3.22753366e-11, 2.65819360e-11, 2.56071372e-11, 2.72703772e-11])
Traceback (most recent call last):
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 559, in <module>
    margin_classifiers_perf(d=50,n=10,approx_tau=1, SNR=10, n_test=1e4, s=1, l1=True)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 266, in margin_classifiers_perf
    err_train_l1 = test_error(w, xs, ys)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 39, in test_error
    pred = x_test @ w
RuntimeError: size mismatch, got 10, 10x50,100