tensor([ 0.0063, -0.0013, -0.0011,  ...,  0.0006, -0.0006,  0.0011])
CMM train_err=0.0, err=48.17500305175781
1.0201048851013184
0.9561037421226501
0.897555947303772
0.8440507054328918
0.7952126860618591
0.750698447227478
0.7101777195930481
0.6733586192131042
0.6399561762809753
0.6097148656845093
0.582395613193512
0.5577719211578369
0.5356347560882568
0.515784502029419
0.49804168939590454
0.4822314977645874
0.4681914448738098
0.45576637983322144
0.44481515884399414
0.4351993799209595
0.4267923831939697
0.41947469115257263
0.4131329655647278
0.4076639413833618
0.402967631816864
0.3989543616771698
0.3955425024032593
0.3926542401313782
0.39022141695022583
0.3881811499595642
0.3864780068397522
0.38506269454956055
0.3838921785354614
0.3829258978366852
0.38213351368904114
0.3814850151538849
0.38095641136169434
0.3805268406867981
0.3801789879798889
0.3798972964286804
0.3796709179878235
0.379488468170166
0.3793419897556305
0.37922531366348267
0.3791314363479614
0.37905675172805786
0.37899768352508545
0.37894946336746216
0.3789117932319641
0.3788824677467346
0.378858357667923
0.37883996963500977
0.3788246512413025
0.37881311774253845
0.37880373001098633
0.37879636883735657
0.3787904381752014
0.37878602743148804
0.378782719373703
0.37877973914146423
0.37877732515335083
0.37877583503723145
0.3787742853164673
0.37877294421195984
0.3787723481655121
0.3787716329097748
0.37877118587493896
0.37877070903778076
0.3787704110145569
0.37877005338668823
0.3787699341773987
0.3787696957588196
0.3787699043750763
0.3787693977355957
0.378769189119339
0.37876951694488525
0.378769189119339
0.3787691593170166
0.3787690997123718
C:\Users\gizem\anaconda3\envs\iw\lib\site-packages\sklearn\svm\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
0.37876930832862854
tensor([ 0.0250, -0.0052, -0.0040,  ...,  0.0023, -0.0027,  0.0044],
       requires_grad=True)
w=1.0, train_err=0.0, err=48.18000030517578
====================l1=========================
CMM train_err=0.0, err=9.480000495910645
3.1110427379608154
3.0102672576904297
2.984755516052246
2.9773049354553223
2.9745264053344727
2.9713668823242188
2.9700253009796143
2.969242572784424
2.9675984382629395
2.9676263332366943
2.966749906539917
2.9663405418395996
2.966749668121338
2.965595245361328
2.9663519859313965
2.965475559234619
2.966014862060547
2.964770793914795
2.965235471725464
2.965301036834717
2.9647960662841797
2.965047836303711
2.965156316757202
2.9646570682525635
2.9640417098999023
2.964519500732422
2.965564727783203
2.964968204498291
2.9643468856811523
2.9647488594055176
2.9646100997924805
2.964280128479004
2.964221239089966
2.964052200317383
2.964168071746826
2.964189052581787
2.9650893211364746
2.963744640350342
2.964367151260376
2.9640772342681885
2.964254856109619
2.9643986225128174
2.964435577392578
2.9651317596435547
2.964353561401367
2.9647834300994873
2.9647207260131836
2.9638466835021973
2.9645490646362305
2.963832139968872
2.963987350463867
2.9643054008483887
2.964118003845215
2.963925361633301
2.9642558097839355
2.9637629985809326
2.964371681213379
2.96453857421875
2.9640867710113525
2.9636881351470947
2.964292526245117
2.9643287658691406
2.9641993045806885
2.9639177322387695
2.9638609886169434
2.963203191757202
2.9640910625457764
2.9636173248291016
2.9638543128967285
2.9649155139923096
2.963592529296875
2.9643874168395996
2.963758707046509
2.9643492698669434
2.964670181274414
2.963578462600708
2.96431827545166
2.9643430709838867
2.963942527770996
2.9646496772766113
2.9642202854156494
2.9640846252441406
2.9641976356506348
2.9641168117523193
2.9636001586914062
2.964578628540039
2.9638144969940186
2.9642508029937744
2.9644393920898438
2.963982105255127
2.9642248153686523
2.9633283615112305
2.9641103744506836
2.964047431945801
2.9642956256866455
2.9639813899993896
2.9648449420928955
2.9634928703308105
2.9645438194274902
2.964015007019043
w=1.0, train_err=0.0, err=5.110000133514404