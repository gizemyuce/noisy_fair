tensor([ 0.0324,  0.0018,  0.0039,  ...,  0.0012, -0.0003,  0.0015])
CMM train_err=0.0, err=45.060001373291016
1.1396615505218506
1.0836704969406128
1.0329914093017578
0.987217366695404
0.9459679126739502
0.9088908433914185
0.8756541013717651
0.8459452390670776
0.8194729089736938
0.7959644198417664
0.7751611471176147
0.7568179368972778
0.740709662437439
0.7266199588775635
0.7143482565879822
0.7037071585655212
0.6945198774337769
0.6866245269775391
0.67987060546875
0.6741206645965576
0.6692457795143127
0.6651327610015869
0.6616792678833008
0.6587910652160645
0.6563863754272461
0.6543924808502197
0.6527455449104309
0.6513903141021729
0.6502794027328491
0.6493723392486572
0.6486326456069946
0.6480324268341064
0.6475462913513184
0.6471532583236694
0.6468364000320435
0.6465814709663391
0.6463769674301147
0.6462126970291138
0.646081805229187
0.6459767818450928
0.645892858505249
0.6458262801170349
0.64577317237854
0.6457304358482361
0.6456971764564514
0.6456708908081055
0.6456493735313416
0.6456323862075806
0.6456186771392822
0.6456081867218018
0.6456001996994019
0.6455932259559631
0.645587682723999
0.6455838680267334
0.6455800533294678
0.6455777287483215
0.6455755829811096
0.6455740928649902
0.6455720663070679
0.645571231842041
0.6455701589584351
0.6455696225166321
0.6455691456794739
0.6455687284469604
0.6455683708190918
0.6455682516098022
0.6455675363540649
0.6455676555633545
0.6455675363540649
0.6455671787261963
0.6455674171447754
0.6455671787261963
0.6455672383308411
0.6455670595169067
0.6455675363540649
0.6455668807029724
C:\Users\gizem\anaconda3\envs\iw\lib\site-packages\sklearn\svm\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
0.6455671787261963
tensor([ 0.0749,  0.0035,  0.0088,  ...,  0.0028, -0.0016,  0.0036],
       requires_grad=True)
w=1.0, train_err=0.0, err=44.980003356933594
====================l1=========================
CMM train_err=0.0, err=6.71999979019165
3.368447780609131
3.36222767829895
3.357365846633911
3.355099678039551
3.357844114303589
3.360272169113159
3.351238250732422
3.352691650390625
3.3510007858276367
3.3560895919799805
3.3442583084106445
3.342721939086914
3.34867000579834
3.3435049057006836
3.3475804328918457
3.347694158554077
3.345010280609131
3.3435816764831543
3.3482306003570557
3.345950126647949
3.3395190238952637
3.340191125869751
3.3381237983703613
3.3398327827453613
3.341848850250244
3.335035800933838
3.338200092315674
3.339350700378418
3.3367881774902344
3.3375205993652344
3.3322248458862305
3.3327717781066895
3.3319764137268066
3.3360986709594727
3.3309226036071777
3.3353769779205322
3.3318021297454834
3.3318684101104736
3.333958148956299
3.3319578170776367
3.3235206604003906
3.3272545337677
3.3264975547790527
3.3281049728393555
3.3264567852020264
3.327547073364258
3.325244665145874
3.325009822845459
3.328382968902588
3.3269968032836914
3.3181498050689697
3.3182315826416016
3.320448875427246
3.3169732093811035
3.3186745643615723
3.318838119506836
3.3171355724334717
3.320159435272217
3.318753719329834
3.3203630447387695
3.3133277893066406
3.311697006225586
3.3131141662597656
3.310530185699463
3.3141846656799316
3.310845375061035
3.315140724182129
3.3169987201690674
3.313786029815674
3.3146753311157227
3.306964159011841
3.3105578422546387
3.306641101837158
3.308703899383545
3.30802059173584
3.3076353073120117
3.3082118034362793
3.3094396591186523
3.311133623123169
3.30692982673645
3.304100513458252
3.302595853805542
3.303755760192871
3.3017287254333496
3.3001389503479004
3.3013086318969727
3.3016128540039062
3.3039395809173584
3.300238609313965
3.301133394241333
3.295766830444336
3.296229839324951
3.294186592102051
3.2981863021850586
3.297199249267578
3.293792724609375
3.2963595390319824
3.2984447479248047
3.294367790222168
3.2960567474365234
3.2885122299194336
3.2894551753997803
3.290879249572754
3.289834499359131
3.2915656566619873
3.2908756732940674
3.290945053100586
3.2879581451416016
3.288787841796875
3.286655902862549
3.2859811782836914
3.283428907394409
3.2878665924072266
3.2874069213867188
3.2867178916931152
3.284095287322998
3.2868781089782715
3.285776376724243
3.2860288619995117
3.282866954803467
3.281290054321289
3.281266927719116
3.2813379764556885
3.2787868976593018
3.279360055923462
3.278920888900757
3.2808384895324707
3.280820846557617
3.2836647033691406
3.2801389694213867
3.2723989486694336
3.2739834785461426
3.2755842208862305
3.273360013961792
3.2750535011291504
3.2730519771575928
3.278092622756958
3.272212028503418
3.2746167182922363
3.2753753662109375
3.27134108543396
3.2713704109191895
3.2706949710845947
3.2713961601257324
3.2722043991088867
3.2709290981292725
3.271367073059082
3.2690017223358154
3.2686076164245605
3.2722136974334717
3.265639543533325
3.265411615371704
3.26356840133667
3.267306327819824
3.266935348510742
3.267714023590088
3.2671046257019043
3.2650413513183594
3.2642905712127686
3.267416000366211
3.26381516456604
3.258841037750244
3.2606019973754883
3.2611474990844727
3.262246608734131
3.260160207748413
3.259509801864624
3.261044502258301
3.2604756355285645
3.261260986328125
3.258082866668701
3.2576794624328613
3.254734992980957
3.257991075515747
3.2596116065979004
3.257859230041504
3.2617945671081543
3.2555060386657715
3.25728702545166
3.257021903991699
3.2543623447418213
3.252537250518799
3.2532262802124023
3.253538131713867
3.2529070377349854
3.25160551071167
3.25252628326416
3.2542014122009277
3.2532358169555664
3.2528066635131836
3.247709274291992
3.248753070831299
3.247802734375
3.2507545948028564
3.2488198280334473
3.248906135559082
3.2493882179260254
3.249976634979248
3.249424934387207
3.249391794204712
3.246215343475342
3.244886875152588
3.244325637817383
3.2450599670410156
3.24420166015625
3.2451653480529785
3.2447457313537598
3.244741916656494
3.2440571784973145
3.2459006309509277
3.241499900817871
3.2407846450805664
3.242265224456787
3.2413809299468994
3.2409729957580566
3.2421083450317383
3.2400107383728027
3.2420835494995117
3.2417614459991455
3.2403364181518555
3.236797332763672
3.23734712600708
3.2353270053863525
3.238924741744995
3.238483190536499
3.2362303733825684
3.2362289428710938
3.2379150390625
3.235518455505371
3.239978551864624
3.2350354194641113
3.2346057891845703
3.235816717147827
3.2351560592651367
3.234463691711426
3.2334706783294678
3.232696056365967
3.2346010208129883
3.2339558601379395
3.233140468597412
3.232466459274292
3.2298789024353027
3.2305564880371094
3.228598117828369
3.2299587726593018
3.2296652793884277
3.229484796524048
3.231348752975464
3.2294485569000244
3.2317726612091064
3.226288318634033
3.224950075149536
3.227473497390747
3.2230536937713623
3.2269551753997803
3.2281405925750732
3.2263245582580566
3.2269606590270996
3.2291178703308105
3.2251415252685547
3.2242767810821533
3.2243008613586426
3.224283218383789
3.2245640754699707
3.224933624267578
3.2222390174865723
3.2241246700286865
3.2238926887512207
3.223815441131592
3.220881938934326
3.219878911972046
3.222480297088623
3.220269203186035
3.220334053039551
3.220902442932129
3.21943998336792
3.2213196754455566
3.220919609069824
3.2192840576171875
3.2170519828796387
3.2188029289245605
3.218808174133301
3.2176756858825684
3.216264247894287
3.21736741065979
3.2174177169799805
3.2161240577697754
3.2179408073425293
3.2174906730651855
3.215014934539795
3.2152092456817627
3.215331554412842
3.2145347595214844
3.214141845703125
3.2137441635131836
3.214951515197754
3.213672637939453
3.21502685546875
3.214259624481201
3.2120461463928223
3.2116453647613525
3.2098422050476074
3.2117819786071777
3.2108957767486572
3.2111353874206543
3.211575984954834
3.211719036102295
3.211174249649048
3.2120280265808105
3.2077083587646484
3.209473133087158
3.208466053009033
3.20766544342041
3.207911491394043
3.2091217041015625
3.2073898315429688
3.2068209648132324
3.208653450012207
3.20766544342041
3.2061092853546143
3.204960823059082
3.205864429473877
3.204677104949951
3.204946279525757
3.20582914352417
3.2055373191833496
3.2053279876708984
3.204810619354248
3.206912040710449
3.2028095722198486
3.201702117919922
3.2024331092834473
3.202868700027466
3.202728271484375
3.202110767364502
3.2032501697540283
3.203697681427002
3.203364372253418
3.2027339935302734
3.198920249938965
3.2012059688568115
3.199643611907959
3.20125675201416
3.1986372470855713
3.199469566345215
3.1990861892700195
3.200127124786377
3.20005464553833
3.1999311447143555
3.1971945762634277
3.1977932453155518
3.196662425994873
3.197920322418213
3.19761323928833
3.1972622871398926
3.1973013877868652
3.1974129676818848
3.198004722595215
3.1975350379943848
3.195241928100586
3.196023464202881
3.195950984954834
3.1966147422790527
3.1951396465301514
3.1953136920928955
3.1961069107055664
3.1965861320495605
3.1954071521759033
3.194528102874756
3.1931190490722656
3.192376136779785
3.193051815032959
3.194340229034424
3.193315267562866
3.1917638778686523
3.1929609775543213
3.193201780319214
3.193924903869629
3.193009853363037
3.190164566040039
3.1902568340301514
3.1902058124542236
3.1910195350646973
3.1899073123931885
3.190791130065918
3.1896467208862305
3.1902403831481934
3.190217971801758
3.190953254699707
3.1869189739227295
3.188969135284424
3.1877880096435547
3.1885151863098145
3.1883225440979004
3.1885910034179688
3.1876745223999023
3.1888279914855957
3.1883904933929443
3.188277006149292
3.187236785888672
3.1861753463745117
3.1864590644836426
3.1864051818847656
3.1869823932647705
3.186161994934082
3.186354637145996
3.1854405403137207
3.1856865882873535
3.18711519241333
3.1836986541748047
3.1845951080322266
3.1837470531463623
3.1837751865386963
3.183694362640381
3.1839776039123535
3.184150218963623
3.183596134185791
3.1830034255981445
3.183689594268799
3.1815199851989746
3.1821370124816895
3.1816163063049316
3.183018684387207
3.1822752952575684
3.182020664215088
3.182386875152588
3.181854248046875
3.1827235221862793
3.1823019981384277
3.1801724433898926
3.180000066757202
Traceback (most recent call last):
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_no_imb.py", line 433, in <module>
    margin_classifiers_perf(d=5000,n=200,approx_tau=1, SNR=10, n_test=1e4, s=1, l1=True)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_no_imb.py", line 295, in margin_classifiers_perf
    l.backward()
  File "C:\Users\gizem\anaconda3\envs\iw\lib\site-packages\torch\_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "C:\Users\gizem\anaconda3\envs\iw\lib\site-packages\torch\autograd\__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt