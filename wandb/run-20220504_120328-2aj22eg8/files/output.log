torch.Size([10, 50])
torch.Size([50])
CMM train_err=0.0, err=44.51499938964844
torch.Size([10, 50])
torch.Size([10, 500])
w=1.0, train_err=0.0, err=44.279998779296875
====================l1=========================
CMM train_err=0.0, err=41.345001220703125
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1.])
     con: array([], dtype=float64)
     fun: -0.7320256596966833
 message: 'Optimization terminated successfully.'
     nit: 9
   slack: array([-3.76579772e-13, -3.89466237e-13, -3.40024405e-14, -2.72989650e-13,
       -3.22269072e-13, -5.02041132e-13, -2.05220137e-13, -1.12038728e-13,
       -5.09717443e-13, -3.72376820e-13, -2.52113664e-13,  1.01188768e-13,
       -3.62628655e-13, -3.29086218e-13, -2.14384943e-13,  1.69436692e-13,
        1.12940034e-13,  3.13273226e-13,  5.15973871e-14,  6.36875687e-13,
       -2.17120307e-14, -5.61193648e-14, -1.46514538e-13,  8.09274213e-14,
       -3.02457038e-13,  5.70586859e-13, -3.37007546e-13,  5.22286240e-13,
       -1.53406428e-13, -1.65987680e-13, -5.93162803e-14, -2.61130457e-13,
        5.59465788e-14,  5.20783666e-14, -3.04124035e-13, -4.94042307e-13,
       -3.74349709e-13,  4.93955483e-14, -2.43379578e-13, -3.63865489e-13,
       -8.28542722e-14, -7.02810728e-14, -2.16512461e-13,  6.79754186e-14,
       -3.24877669e-13, -2.22371503e-13,  7.16671097e-14, -1.14467380e-13,
        7.02054936e-13, -2.05196147e-13,  5.09812516e-12,  1.89537017e+00,
        1.75622187e-12,  2.87508089e-12,  1.28095987e-12,  5.36797438e-12,
        2.01599046e-12,  1.83381531e-12,  7.52810173e-12,  3.68771193e-12,
        2.85899341e-12,  1.50106773e-12,  2.41656369e-12,  3.82220923e-12,
        2.19104930e-12,  1.42043550e-12,  1.50404019e-12,  1.34216726e-12,
        1.58194748e-12,  1.22579287e-12,  1.64019558e-12,  1.80552835e-12,
        1.88105223e-12,  1.54198564e-12,  2.47753776e-12,  1.19042019e-12,
        3.68922774e-12,  1.22314468e-12,  1.98392997e-12,  2.44855323e-12,
        1.77394123e-12,  2.16280896e-12,  1.56311744e-12,  1.54395423e-12,
        1.99477301e-12,  1.04629825e-01,  3.45752435e-12,  1.57979514e-12,
        2.59407171e-12,  3.24628763e-12,  1.86897038e-12,  1.73161914e-12,
        2.36665199e-12,  1.52962770e-12,  2.20732174e-12,  2.37891838e-12,
        1.56038741e-12,  2.01184384e-12,  1.16785252e-12,  2.00551141e-12,
        5.60725244e-01,  1.13662365e+00,  3.91313545e-01,  4.86561023e-12,
        1.48244113e+00,  1.35596033e+00,  8.19177625e-02,  5.11414439e-01,
        1.70144720e+00,  9.84138505e-02, -3.72057940e-11])
  status: 0
 success: True
       x: array([2.73735247e-12, 9.47685087e-01, 8.95112156e-13, 1.57403527e-12,
       8.01614469e-13, 2.93500776e-12, 1.11060530e-12, 9.72927018e-13,
       4.01890959e-12, 2.03004438e-12, 1.55555354e-12, 6.99939481e-13,
       1.38959617e-12, 2.07564772e-12, 1.20271712e-12, 6.25499402e-13,
       6.95550078e-13, 5.14447016e-13, 7.65175047e-13, 2.94458592e-13,
       8.30953804e-13, 9.30823859e-13, 1.01378339e-12, 7.30529110e-13,
       1.38999740e-12, 3.09916667e-13, 2.01311765e-12, 3.50429219e-13,
       1.06866820e-12, 1.30727045e-12, 9.16628757e-13, 1.21196971e-12,
       7.53585431e-13, 7.45937931e-13, 1.14944852e-12, 5.23149126e-02,
       1.91593703e-12, 7.65199796e-13, 1.41872565e-12, 1.80507656e-12,
       9.75912328e-13, 9.00950109e-13, 1.29158222e-12, 7.30826139e-13,
       1.26609970e-12, 1.30064494e-12, 7.44360152e-13, 1.06315561e-12,
       2.32898793e-13, 1.10535378e-12, 2.36077270e-12, 9.47685087e-01,
       8.61109715e-13, 1.30104562e-12, 4.79345397e-13, 2.43296662e-12,
       9.05385163e-13, 8.60888290e-13, 3.50919214e-12, 1.65766756e-12,
       1.30343987e-12, 8.01128249e-13, 1.02696751e-12, 1.74656151e-12,
       9.88332177e-13, 7.94936094e-13, 8.08490111e-13, 8.27720243e-13,
       8.16772434e-13, 9.31334279e-13, 8.09241773e-13, 8.74704495e-13,
       8.67268848e-13, 8.11456532e-13, 1.08754036e-12, 8.80503526e-13,
       1.67611010e-12, 8.72715459e-13, 9.15261774e-13, 1.14128277e-12,
       8.57312477e-13, 9.50839251e-13, 8.09532009e-13, 7.98016298e-13,
       8.45324489e-13, 5.23149126e-02, 1.54158732e-12, 8.14595345e-13,
       1.17534607e-12, 1.44121107e-12, 8.93058055e-13, 8.30669036e-13,
       1.07506976e-12, 7.98801558e-13, 9.41222034e-13, 1.07827344e-12,
       8.16027262e-13, 9.48688231e-13, 9.34953729e-13, 9.00157630e-13])
(50,)
<built-in method size of Tensor object at 0x00000259B6187740>
Traceback (most recent call last):
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 564, in <module>
    margin_classifiers_perf(d=50,n=10,approx_tau=1, SNR=10, n_test=1e4, s=1, l1=True)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 271, in margin_classifiers_perf
    err_train_l1 = test_error(w, xs, ys)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin_interp.py", line 39, in test_error
    pred = x_test @ w
RuntimeError: expected scalar type Float but found Double