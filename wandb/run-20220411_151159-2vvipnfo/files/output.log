tensor([ 0.0332, -0.0027,  0.0041,  ...,  0.0063,  0.0030,  0.0017])
CMM train_err=0.0, err=44.57500076293945
tensor([nan, nan, nan,  ..., nan, nan, nan], requires_grad=True)
w=1.0, train_err=100.0, err=100.0
tensor([nan, nan, nan,  ..., nan, nan, nan], requires_grad=True)
w=1.0, train_err=100.0, err=100.0
tensor([nan, nan, nan,  ..., nan, nan, nan], requires_grad=True)
w=1.0, train_err=100.0, err=100.0
====================l1=========================
CMM train_err=0.0, err=7.72499942779541
C:\Users\gizem\anaconda3\envs\iw\lib\site-packages\sklearn\svm\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
129207.6875
92474.3671875
63890.5703125
42671.38671875
29193.458984375
21161.943359375
11482.06640625
6414.2333984375
3335.682861328125
7029.55224609375
173827.078125
132523.265625
98974.5390625
72474.6796875
51830.90625
35981.4375
24569.126953125
15999.568359375
11433.9931640625
23856776.0
23807344.0
23758038.0
23708792.0
23659604.0
23610514.0
23561464.0
23512462.0
23463616.0
23414716.0
23365886.0
23317126.0
23268440.0
23219758.0
23171224.0
23122674.0
23074242.0
23025838.0
22977444.0
22929136.0
22880850.0
22832622.0
22784480.0
22736204.0
22687946.0
22639820.0
22591794.0
22543876.0
22496028.0
22448290.0
22400608.0
22353082.0
22305610.0
22258204.0
22210866.0
22163632.0
22116432.0
22069326.0
22022282.0
21975348.0
21928470.0
21881638.0
21834888.0
21788212.0
21741518.0
21694884.0
21648318.0
21601766.0
21555310.0
21508934.0
21462604.0
21416354.0
21370128.0
21324002.0
21277950.0
21231964.0
21185956.0
21140146.0
21094356.0
21048636.0
21002914.0
20957220.0
20911662.0
20866144.0
20820660.0
20775220.0
20729858.0
20684538.0
20639260.0
20593992.0
20548828.0
20503678.0
20458582.0
20413508.0
20368542.0
20323626.0
20278754.0
20233880.0
20189148.0
20144484.0
20099874.0
20055280.0
20010734.0
19966222.0
19921712.0
19877276.0
19832898.0
19788614.0
19744396.0
19700230.0
19656154.0
19612182.0
19568294.0
19524530.0
19480830.0
19437232.0
19393714.0
19350198.0
19306826.0
19263474.0
19220236.0
19177088.0
19134054.0
19091070.0
19048180.0
19005334.0
18962592.0
18919832.0
18877224.0
18834648.0
18792120.0
18749680.0
18707290.0
18665030.0
18622882.0
18580802.0
18538740.0
18496850.0
18455020.0
18413194.0
18371396.0
18329672.0
18288008.0
18246482.0
18205058.0
18163702.0
18122418.0
18081192.0
18040058.0
17998932.0
17957862.0
17916810.0
17875856.0
17834942.0
17794094.0
17753290.0
17712628.0
17671950.0
Traceback (most recent call last):
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin.py", line 432, in <module>
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin.py", line 291, in margin_classifiers_perf
    l = loss_average_poly(w, b, z1s, z2s, n1, n2) + torch.norm(w, p=1)
  File "C:\Users\gizem\anaconda3\envs\iw\lib\site-packages\torch\_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "C:\Users\gizem\anaconda3\envs\iw\lib\site-packages\torch\autograd\__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt