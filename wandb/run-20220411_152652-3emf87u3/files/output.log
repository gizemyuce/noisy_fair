tensor([ 3.0595e-02,  1.1129e-03,  1.7626e-03,  ..., -2.0483e-03,
         4.9971e-03,  3.1681e-05])
CMM train_err=0.0, err=45.939998626708984
tensor([nan, nan, nan,  ..., nan, nan, nan], requires_grad=True)
w=1.0, train_err=100.0, err=100.0
tensor([nan, nan, nan,  ..., nan, nan, nan], requires_grad=True)
w=1.0, train_err=100.0, err=100.0
tensor([nan, nan, nan,  ..., nan, nan, nan], requires_grad=True)
w=1.0, train_err=100.0, err=100.0
====================l1=========================
CMM train_err=0.0, err=5.5
C:\Users\gizem\anaconda3\envs\iw\lib\site-packages\sklearn\svm\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
192848.875
147427.1875
110097.3046875
81316.4140625
13375932.0
13326279.0
13276756.0
13227332.0
13178030.0
13128826.0
13079695.0
13030660.0
12981740.0
12932917.0
12884245.0
12835647.0
12787158.0
12738765.0
12690469.0
12642273.0
12594157.0
12546152.0
12498280.0
12450497.0
12402815.0
12355210.0
12307709.0
12260326.0
12213049.0
12165873.0
12118774.0
12071805.0
12024988.0
11978290.0
11931747.0
11885315.0
11838994.0
11792748.0
11746619.0
11700620.0
11654697.0
11608876.0
11563118.0
11517477.0
11471944.0
11426527.0
11381260.0
11336189.0
11291260.0
11246396.0
11201659.0
11157070.0
11112550.0
11068094.0
11023645.0
10979307.0
10935101.0
10890919.0
10846880.0
10802937.0
10759046.0
10715217.0
10671500.0
10627890.0
10584403.0
10540946.0
10497593.0
10454372.0
10411246.0
10368240.0
10325341.0
10282564.0
10239944.0
10197440.0
10155090.0
10112815.0
10070665.0
10028496.0
9986481.0
9944542.0
9902707.0
9861037.0
9819512.0
9777977.0
9736539.0
9695231.0
9654024.0
9612963.0
9571991.0
9531169.0
9490520.0
9449943.0
9409495.0
9369136.0
9328894.0
9288733.0
9248737.0
9208811.0
9168936.0
9129222.0
9089644.0
9050183.0
9010905.0
8971715.0
8932632.0
8893685.0
8854820.0
8816066.0
8777443.0
8738950.0
8700600.0
8662363.0
8624322.0
8586429.0
8548663.0
8510959.0
8473401.0
8435924.0
8398590.0
8361318.5
8324157.0
8287065.0
8250106.0
8213229.0
8176455.5
8139749.0
8103203.0
8066787.5
8030489.5
7994268.0
7958174.0
7922186.5
7886381.0
7850640.5
7815087.0
7779610.0
7744197.0
7708890.0
7673743.0
7638740.5
7603911.5
7569198.5
7534620.5
7500130.5
7465741.5
7431466.5
7397281.5
7363234.5
7329263.5
7295415.0
7261699.5
7228099.0
7194594.0
7161218.5
7127961.5
7094795.5
7061694.0
7028714.5
6995868.0
6963127.0
6930499.5
6897942.0
6865564.5
6833312.5
6801206.0
6769198.0
6737334.0
6705505.5
6673791.0
6642166.0
6610610.5
6579196.5
6547833.5
6516648.5
6485609.0
6454715.5
6423892.5
6393229.5
6362671.0
6332208.0
6301806.5
6271518.0
6241340.5
6211239.5
Traceback (most recent call last):
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin.py", line 433, in <module>
    margin_classifiers_perf(d=5000,n=200,approx_tau=1, SNR=10, n_test=1e4, s=1, l1=True)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin.py", line 291, in margin_classifiers_perf
    l = loss_average_poly(w, b, z1s, z2s, n1, n2) + torch.norm(w, p=1)
  File "c:\Users\gizem\Documents\GitHub\noisy_fair\margin.py", line 26, in loss_average_poly
    return (torch.sum(1./(z1s @ v)) + b * torch.sum(1./(z2s @ v))) /(n1+b*n2)
  File "C:\Users\gizem\anaconda3\envs\iw\lib\site-packages\torch\_tensor.py", line 26, in wrapped
    @functools.wraps(f, assigned=assigned)
KeyboardInterrupt